Hereâ€™s a comprehensive code example for implementing a predictive maintenance model in Python, covering data preprocessing, feature engineering, model training, and evaluation.

### Steps and Code for Predictive Maintenance:

1. **Data Loading and Exploration**
2. **Feature Engineering**
3. **Modeling with Random Forest and LSTM**
4. **Evaluation**

We will use synthetic data to demonstrate this process.

### Code Implementation

```python
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam

# Generate synthetic data
np.random.seed(0)
data = pd.DataFrame({
    'temperature': np.random.normal(70, 10, 1000),
    'vibration': np.random.normal(50, 5, 1000),
    'pressure': np.random.normal(100, 15, 1000),
    'time_since_last_failure': np.random.exponential(5, 1000),
    'failure': np.random.choice([0, 1], 1000, p=[0.95, 0.05])
})

# Data Exploration
print(data.describe())
print(data['failure'].value_counts())

# Feature Engineering
data['temp_vib_ratio'] = data['temperature'] / data['vibration']
data['pressure_drop'] = data['pressure'].diff().fillna(0)

# Splitting data
X = data.drop(columns='failure')
y = data['failure']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features for LSTM and RandomForest
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Random Forest Model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_scaled, y_train)
rf_pred = rf_model.predict(X_test_scaled)

# Evaluation - Random Forest
rf_precision = precision_score(y_test, rf_pred)
rf_recall = recall_score(y_test, rf_pred)
rf_f1 = f1_score(y_test, rf_pred)
print(f"Random Forest - Precision: {rf_precision:.2f}, Recall: {rf_recall:.2f}, F1 Score: {rf_f1:.2f}")

# LSTM Model for time-series data
X_train_lstm = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_lstm = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

lstm_model = Sequential([
    LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=True),
    LSTM(32),
    Dense(1, activation='sigmoid')
])
lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)

# Predictions and Evaluation - LSTM
lstm_pred = (lstm_model.predict(X_test_lstm) > 0.5).astype("int32").flatten()
lstm_precision = precision_score(y_test, lstm_pred)
lstm_recall = recall_score(y_test, lstm_pred)
lstm_f1 = f1_score(y_test, lstm_pred)
print(f"LSTM - Precision: {lstm_precision:.2f}, Recall: {lstm_recall:.2f}, F1 Score: {lstm_f1:.2f}")
```

### Explanation of Each Step:

1. **Data Generation and Exploration**:
   - We create synthetic data with columns like `temperature`, `vibration`, `pressure`, `time_since_last_failure`, and a binary `failure` column.
   - Basic exploratory steps like `describe()` and failure count help understand data distribution.

2. **Feature Engineering**:
   - `temp_vib_ratio`: Ratio between temperature and vibration as an indicator of overheating.
   - `pressure_drop`: Difference in pressure between consecutive readings, potentially indicating leakage or malfunction.

3. **Data Splitting and Standardization**:
   - Split data into train and test sets, then scale the features for better model performance.

4. **Modeling**:
   - **Random Forest**: Trains a simple, interpretable model to handle complex interactions in the data.
   - **LSTM**: Designed to capture time-based patterns, which is especially valuable if data includes sequences or time steps.

5. **Evaluation**:
   - Calculating precision, recall, and F1-score for each model gives insight into its effectiveness in predicting failures.
